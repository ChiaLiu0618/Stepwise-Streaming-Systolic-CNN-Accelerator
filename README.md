# Stepwise-Streaming Systolic CNN Accelerator

### üìÖ May 2025 ‚Äì July 2025  
**Tools:** SystemVerilog, Synopsys (VCS, Verdi, Design Compiler), ARM SRAM Compiler, PyTorch  
**Target Process:** TSMC 40 nm  
**Performance:** 129 GFLOPs/s (INT8-equivalent) @ 500 MHz  
**Area:** 412.7 K ¬µm¬≤  

---

## üß© Overview

This project implements a **CNN accelerator ASIC** based on a **stepwise-streaming systolic array** architecture with **cached weight dataflow**.  
The design focuses on minimizing off-chip memory access through **cyclic weight reuse** within each Processing Element (PE), achieving high throughput and energy efficiency.

---

## üöÄ Key Features

- **Systolic Array Architecture:**  
  4 √ó 9 √ó 8 PE grid optimized for INT8 multiply‚Äìaccumulate (MAC) operations.

- **Cached Weight Dataflow:**  
  Enables cyclic weight reuse within PEs, significantly reducing memory bandwidth demands.

- **Stepwise Streaming:**  
  Tiled activation scheduling ensures continuous streaming of feature maps and balanced PE utilization.

- **Fused MAC‚ÄìReLU‚ÄìMax Units:**  
  On-chip fusion of compute and nonlinearity operations (MAC ‚Üí ReLU ‚Üí Max-pool) to reduce memory access overhead.

- **Quantized Model Deployment:**  
  End-to-end flow from **PyTorch model quantization** ‚Üí **custom ISA compilation** ‚Üí **RTL simulation**.

- **ASIC Implementation Flow:**  
  - RTL ‚Üí Synthesis ‚Üí Gate-level Simulation  
  - Tools: **Synopsys VCS**, **Design Compiler**, **Verdi**  
  - SRAM generated via **ARM SRAM Compiler**  
  - Technology: **TSMC 40 nm**

---

## üìä Results

| Metric | Value | Notes |
|:--|:--|:--|
| Frequency | 500 MHz | Nominal TT / 1.1 V / 25 ¬∞C |
| Throughput | 129 GFLOPs/s | INT8-equivalent |
| Total Area | 412.7 K ¬µm¬≤ | Post-synthesis |
| Model Tested | MNIST | Quantized 3√ó3 Conv + FC network |
| Verification | RTL + Post-synthesis simulation | Verdi waveform inspection |

---

## üß† Architecture Highlights

- **Processing Element (PE):**  
  Each PE performs multiply‚Äìaccumulate and passes partial sums in a systolic fashion.  
  Cached weights are reused for multiple activation tiles.

- **On-Chip SRAM Buffering:**  
  Dual-bank SRAM buffers for activations and partial sums to support stepwise streaming.

- **Custom ISA Controller:**  
  Decouples activation load, compute, and output phases to reduce control overhead.

- **Dataflow Optimization:**  
  Activation tiling and scheduling ensure maximum array utilization for convolutional workloads.

---

## üß™ Simulation and Verification

- RTL verification performed using **Synopsys VCS**  
- Waveform debugging and signal tracing with **Verdi**  
- Post-synthesis functional verification using **Design Compiler**  
- Testbench stimuli generated from **quantized PyTorch tensors**  
- Output results matched against a **reference software model** to ensure functional correctness  
- Deployed the accelerator on a **quantized MNIST inference task**, demonstrating correct end-to-end mapping from software model to hardware execution

---

---

## üìö References

[1] Y.-H. Chen, T. Krishna, J. S. Emer, and V. Sze,  
‚Äú**Eyeriss: An Energy-Efficient Reconfigurable Accelerator for Deep Convolutional Neural Networks**,‚Äù  
*IEEE Journal of Solid-State Circuits*, vol. 52, no. 1, pp. 127‚Äì138, Jan. 2017.  
DOI: [10.1109/JSSC.2016.2616357](https://doi.org/10.1109/JSSC.2016.2616357)

[2] N. P. Jouppi *et al.*,  
‚Äú**In-Datacenter Performance Analysis of a Tensor Processing Unit**,‚Äù  
*Proceedings of the 44th Annual International Symposium on Computer Architecture (ISCA)*, pp. 1‚Äì12, 2017.  
DOI: [10.1145/3079856.3080246](https://doi.org/10.1145/3079856.3080246)

[3] Xilinx Inc.,  
‚Äú**DPUCADX8G IP Core Product Brief: Deep Learning Processor Unit (DPU) for Alveo U200/U250**,‚Äù  
2020. [Online]. Available: [https://docs.amd.com/r/1.2-English/ug1414-vitis-ai/Alveo-U200/U250-DPUCADX8G](https://docs.amd.com/r/1.2-English/ug1414-vitis-ai/Alveo-U200/U250-DPUCADX8G)

---

## üßæ License

Due to copyright restrictions, this repository includes only the synthesis and simulation results.

---

### Author
**Chia-Heng Liu**  
M.Eng. ECE, Cornell University  
Email: [chialiu0618@gmail.com](mailto:chialiu0618@gmail.com)  
GitHub: [ChiaLiu0618](https://github.com/ChiaLiu0618)  
LinkedIn: [linkedin.com/in/chia-heng-liu-chialiu20020618](https://www.linkedin.com/in/chia-heng-liu-chialiu20020618)
